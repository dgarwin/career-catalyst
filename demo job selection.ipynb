{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94ba866a-46cd-49f3-ac7c-661b93c122ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import string\n",
    "from google.cloud import storage\n",
    "import json\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb7780d-df50-402c-8cbf-e8f654f719b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dialogue = \"\"\"\n",
    "C\n",
    "Welcome to Career Catalyst! We are here to support you in discovering the career that has you fulfilled. If you could have anything in your career, what would it be?\n",
    "\n",
    "Before we begin, please also enter your resume on the left tool bar.\n",
    "\n",
    "Your message\n",
    "\n",
    "Hi Career catalyst, I want to work on interesting, practical problems that impact a large number of users. I want to work in a collaborative environment with a team of intelligent people. I want there to be some work-life balance and not have my impact completely tied to hours worked.\n",
    "\n",
    "C\n",
    "question: Say more about your aspirations for the next 2 years?\n",
    "\n",
    "In the short term, I want to transition to a more technical role, more like a machine learning engineer. I want to build cool, impactful products.\n",
    "\n",
    "C\n",
    "question: Say more about what you imagine your life style to be and how work supports that.\n",
    "\n",
    "I will be learning on the side and working on side projects. But I also have time for other hobbies and contributing to the community. While my work as a data scientist/ml engineer is a big part of what I care about, I have a well-rounded life.\n",
    "\n",
    "C\n",
    "question: What is the highest level of impact you can envision?\n",
    "\n",
    "I'd like to work on products that impact millions of people. I want some element of research to be a part of it, but prefer doing applied work with all the technical real-world complexities that arise.\n",
    "\n",
    "C\n",
    "question: Say more about what your goals are for your career in the next 5 years.\n",
    "\n",
    "I'd like to then transition to more of a managerial role and really understand what it takes to lead teams of people in complex organizations.\n",
    "\n",
    "C\n",
    "question: Say more about your aspirations for the next 10 years.\n",
    "\n",
    "In 10 years, I'd like to be building something from the ground up. I've picked a domain that I'm really passionate about and have a strong network of contacts I can draw upon. I have a well-rounded skill set, and also know when to delegate.\n",
    "\n",
    "C\n",
    "question: Say more about what role finance and management will play in your career.\n",
    "\n",
    "Being financially independent is important to me. As is the ability to build a supporting team. I want financial independence and for my investments and businesses to pay for my lifestyle while growing somewhat independently of my attention.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07af4e2e-8699-40a2-bb27-629f77509f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from vertexai.language_models import TextEmbeddingInput, TextEmbeddingModel\n",
    "\n",
    "\n",
    "def embed_text(\n",
    "    texts,\n",
    "    task: str = \"RETRIEVAL_DOCUMENT\",\n",
    "    model_name: str = \"textembedding-gecko@002\",\n",
    ") -> List[List[float]]:\n",
    "    \"\"\"Embeds texts with a pre-trained, foundational model.\"\"\"\n",
    "    model = TextEmbeddingModel.from_pretrained(model_name)\n",
    "    inputs = [TextEmbeddingInput(text, task) for text in texts]\n",
    "    embeddings = model.get_embeddings(inputs)\n",
    "    return [embedding.values for embedding in embeddings]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa46f4aa-9471-47e1-a922-ef82c0202c47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = ! gcloud config get-value project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\"\n",
    "if PROJECT_ID == \"(unset)\":\n",
    "    print(f\"Please set the project ID manually below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c0cd81-abaf-40ca-b6d4-c3aabb7312f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3c146c4-5e0e-441d-84ce-b5dc6ddbcc2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = \"vs_quickstart_deployed_143\"\n",
    "my_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(\n",
    "    index_endpoint_name='projects/809892116196/locations/us-central1/indexEndpoints/2671712100425924608'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5ced652-2faf-4c23-9541-038a10e427a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "model = GenerativeModel(model_name=\"gemini-1.0-pro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeaa5622-278d-4bf1-b96e-598c341744c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_pdf(file_location):\n",
    "    reader = PdfReader(file_location)\n",
    "    accum = []\n",
    "    for page in reader.pages:\n",
    "        accum.append(page.extract_text())\n",
    "    return '\\n'.join(accum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5efd7555-a54f-4e4e-8d43-2320b7ff0d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aaron_resume = read_pdf('Data Analyst/Aaron Li Resume 2023.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9507a47-3c38-4748-9b43-d719f479f9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_pre = \"\"\"\n",
    "You are a seasoned career coach. you have coached dozens of clients. You help clients discover what they want out of their career. \n",
    "\n",
    "You are giving advice to a data analyst with the resume below. He wants to switch to a more technical data scientist or machine learning engineer\n",
    "role and is seeking your guidance to improve.\n",
    "what does his resume look like 3 years. He has also had a chat with you\n",
    "\n",
    "resume: {resume}\n",
    "chat contents: {chat_contents}\n",
    "resume in three years:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "hypothetical_resume = model.generate_content(\n",
    "        # Add an example query\n",
    "        prompt_pre.format(\n",
    "            resume=aaron_resume,\n",
    "            chat_contents=dialogue\n",
    "                         )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "966a41b0-6984-4c69-9bae-99cb133e4ea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Aaron Li - Data Scientist / Machine Learning Engineer\n",
       "\n",
       "**[Your website or portfolio link here]** | (314) 250-4579 | New York, NY\n",
       "\n",
       "**Summary of Qualifications:**\n",
       "\n",
       "Seasoned data scientist with over 5 years of experience specializing in the application of AI and machine learning to solve complex business problems. Proven ability to design and implement ETL pipelines, analyze large datasets, and build models that deliver significant business impact. Expert in various programming languages including Python, SQL, and R, as well as machine learning libraries like TensorFlow and PyTorch. Passionate about driving innovation and collaborating with cross-functional teams to achieve common goals.\n",
       "\n",
       "**Technical Skills:**\n",
       "\n",
       "* **Programming Languages:** Python, SQL, R, Java\n",
       "* **Machine Learning Libraries:** TensorFlow, PyTorch, Scikit-learn\n",
       "* **Data Analysis Tools:** Pandas, NumPy, Spark, Airflow\n",
       "* **Cloud Platforms:** AWS, Azure\n",
       "* **Visualization Tools:** Tableau, Power BI, Grafana\n",
       "\n",
       "**Experience:**\n",
       "\n",
       "**Machine Learning Engineer** | Acme Corporation | New York, NY | 2024 - Present\n",
       "\n",
       "* Developed and deployed machine learning models that improved customer churn prediction by 20%, leading to a 15% increase in customer retention.\n",
       "* Led the design and implementation of an automated system for anomaly detection in financial transactions, preventing over $1 million in fraudulent activity.\n",
       "* Developed a natural language processing model for sentiment analysis of social media data, generating insights that informed product development and marketing campaigns.\n",
       "* Built and deployed a recommendation engine for e-commerce platform, resulting in a 10% increase in average order value.\n",
       "\n",
       "**Data Scientist** | Apex Inc. | San Francisco, CA | 2022 - 2024\n",
       "\n",
       "* Designed and implemented ETL pipelines for processing large-scale datasets from diverse sources.\n",
       "* Performed exploratory data analysis and identified key insights that informed business decisions.\n",
       "* Built and deployed machine learning models for various applications, including fraud detection, customer segmentation, and predictive maintenance.\n",
       "* Collaborated with cross-functional teams to translate data insights into actionable recommendations and optimize business processes.\n",
       "\n",
       "**Education:**\n",
       "\n",
       "Master of Science in Data Science, Columbia University, New York, NY (2022)\n",
       "Bachelor of Science in Mathematics, University of California, Berkeley (2020)\n",
       "\n",
       "**Projects:**\n",
       "\n",
       "* Developed a deep learning model for image classification that achieved 95% accuracy on the ImageNet dataset.\n",
       "* Built a real-time sentiment analysis tool for Twitter data that analyzes public opinion on trending topics.\n",
       "* Implemented a collaborative filtering algorithm for movie recommendations that personalized user experience.\n",
       "\n",
       "**Leadership & Activities:**\n",
       "\n",
       "* Co-organized a machine learning workshop for aspiring data scientists.\n",
       "* Mentored junior data science interns on applying machine learning techniques to real-world problems.\n",
       "* Actively participated in meetups and conferences to stay informed about the latest advancements in the field.\n",
       "\n",
       "**Key Strengths:**\n",
       "\n",
       "* Strong analytical and problem-solving skills.\n",
       "* Deep understanding of machine learning algorithms and their applications.\n",
       "* Excellent communication and collaboration skills.\n",
       "* Ability to translate complex data insights into actionable recommendations.\n",
       "* Passionate about innovation and applying data science to real-world problems.\n",
       "\n",
       "This resume reflects your aspirations and goals, combining your passion for impactful work, research, and leadership with a focus on machine learning and data science expertise. It emphasizes your technical skills, achievements, and leadership experience, positioning you as a strong candidate for technical data scientist and machine learning engineer roles. Remember to personalize your resume further by incorporating specific details and experiences relevant to each job application. I'm confident that with your dedication and continued learning, you will achieve your dream career path! \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(hypothetical_resume.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc77ff2f-186b-4a59-9bc1-d5224bdfa3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hypothetical_resume_embedding = embed_text(texts=[hypothetical_resume.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "840dc24c-ab48-49e9-b6df-be4d4a318356",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatchNeighbor(id='5', distance=0.03427734971046448, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[])\n",
      "0.03 5\n",
      "MatchNeighbor(id='41', distance=0.031075958162546158, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[])\n",
      "0.03 41\n",
      "MatchNeighbor(id='9', distance=0.02756562829017639, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[])\n",
      "0.03 9\n",
      "MatchNeighbor(id='3', distance=0.0209933053702116, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[])\n",
      "0.02 3\n",
      "MatchNeighbor(id='30', distance=0.019494637846946716, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[])\n",
      "0.02 30\n",
      "MatchNeighbor(id='27', distance=0.01804642751812935, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[])\n",
      "0.02 27\n",
      "MatchNeighbor(id='46', distance=0.01592842862010002, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[])\n",
      "0.02 46\n",
      "MatchNeighbor(id='25', distance=0.015420296229422092, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[])\n",
      "0.02 25\n",
      "MatchNeighbor(id='17', distance=0.014436919242143631, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[])\n",
      "0.01 17\n",
      "MatchNeighbor(id='12', distance=0.013608276844024658, feature_vector=[], crowding_tag='0', restricts=[], numeric_restricts=[])\n",
      "0.01 12\n"
     ]
    }
   ],
   "source": [
    "response = my_index_endpoint.find_neighbors(\n",
    "    deployed_index_id = DEPLOYED_INDEX_ID,\n",
    "    queries = [hypothetical_resume_embedding[0]],\n",
    "    num_neighbors = 10\n",
    ")\n",
    "\n",
    "# show the results\n",
    "for idx, neighbor in enumerate(response[0]):\n",
    "    print(neighbor)\n",
    "    print(f\"{neighbor.distance:.2f} {neighbor.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44a56dae-d4be-495f-9e32-1bfac7ffe13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('career-catalyst-standard-resume/standardized-resume-text/2024-04-20/data_analyst_resumes.jsonl') as f:\n",
    "    resumes = pd.DataFrame([json.loads(l) for l in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e4003d5-53da-474e-b713-14e8f13390eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# EXPERIENCE\\n\\n - Quality Technician at Intralox, performing quality inspections and tests, conducting root cause analysis, and collaborating with teams to improve processes.\\n- Quality Manager at IWS Gas and Supply, leading a $500k lab expansion project, ensuring ISO 17025 compliance, overseeing quality control programs, and implementing quality training.\\n- Manufacturing Data Analyst at IWS Gas and Supply, analyzing data to identify trends and opportunities for improvement, developing data collection systems, and conducting internal audits.\\n- Skilled in quality assurance, professional software, measurement tools, root cause analysis, statistical process control, documentation, quality management systems, data analysis, process optimization, statistical tools, data visualization, predictive maintenance, cross-functional collaboration, chemical testing, laboratory safety, instrumentation, data interpretation, quality control, and technical documentation.\\n- Proficient in Excel, SigmaXL, Solid Works, AutoCAD, Microsoft Teams, Microsoft Office, and Power BI.\\n# INDUSTRIES\\n\\n Manufacturing\\nChemical\\nOil and Gas\\n# SKILLS\\n\\n **Top 10 Skills:**\\n\\n1. Data Analysis\\n2. Data Visualization\\n3. Python\\n4. SQL\\n5. Power BI\\n6. Machine Learning\\n7. Data Warehousing\\n8. Data Extraction\\n9. Data Cleaning\\n10. Data Manipulation']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumes.iloc[5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0593bf1-6b28-462b-9fc0-9864d62bcad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_resumes = resumes.iloc[[5, 41, 9, 3, 30, 27, 46, 25, 17, 12]]['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d816590-236b-4f6b-9e67-1be2a3cccb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_augmented_with_data = \"\"\"\n",
    "You are a seasoned career coach. you have coached dozens of clients. You help clients discover what they want out of their career. \n",
    "\n",
    "You are giving advice to a data analyst with the resume below. He wants to switch to a more technical data scientist or machine learning engineer\n",
    "role and is seeking your guidance to improve.\n",
    "what does his resume look like 3 years. He has also had a chat with you.\n",
    "Use the real resumes to make the output more realistic.\n",
    "\n",
    "resume: {resume}\n",
    "other real resumes: {real_resumes}\n",
    "chat contents: {chat_contents}\n",
    "resume in three years:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "hypothetical_resume = model.generate_content(\n",
    "        # Add an example query\n",
    "        prompt_pre.format(\n",
    "            resume=aaron_resume,\n",
    "            real_resumes = real_resumes,\n",
    "            chat_contents=dialogue\n",
    "                         )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "96b7749d-8665-4a4a-9725-bf973552a7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## AARON LI\n",
       "\n",
       "**(314) 250-4579** | **aaron.li.workday@gmail.com** | **New York, NY**\n",
       "\n",
       "**SUMMARY OF QUALIFICATIONS**\n",
       "\n",
       "Aaron brings over five years of experience in data analysis, business intelligence, and machine learning. He is proficient in SQL, Python, and cloud platforms, with a strong focus on building machine learning models and developing ETL pipelines. Aaron demonstrates expertise in data visualization, using tools like Grafana, Tableau, and Power BI for effective communication and decision-making. \n",
       "\n",
       "Aaron is recognized for his problem-solving abilities, collaborative spirit, and passion for learning. \n",
       "\n",
       "\n",
       "** EDUCATION** \n",
       "\n",
       "\n",
       "* **Master of Science in Business Analytics**, Financial Technology Analysis Track (2023)\n",
       "  * Olin School of Business, Washington University in St. Louis, St. Louis, MO\n",
       "\n",
       "* **Bachelor of Business Administration** (2022)\n",
       "  * Major in Finance\n",
       "  * Minor in Data Science\n",
       "  * Northeastern University, Boston, MA\n",
       "\n",
       "\n",
       "**PROFESSIONAL EXPERIENCE**\n",
       "\n",
       "**Machine Learning Engineer** (2024 - Present)\n",
       "* **Acme Corporation**, New York, NY\n",
       "\n",
       "* Developed and deployed machine learning models for various use cases, including churn prediction, fraud detection, and customer segmentation.\n",
       "* Implemented end-to-end machine learning pipelines using cloud platforms (e.g., AWS, GCP).\n",
       "* Conducted A/B testing and monitored model performance for continuous improvement. \n",
       "* Contributed to the development of an automated Machine Learning platform for faster experimentation and deployment.\n",
       "* Collaborated effectively with cross-functional teams to translate business needs into technical solutions.\n",
       "\n",
       "\n",
       "**Data Analyst** (2022 - 2024)\n",
       "* **Haddee Education, Jersey City, NJ**\n",
       "\n",
       "* Built ETL pipelines using Python for loading and processing large datasets.\n",
       "* Developed interactive dashboards in Grafana using SQL and Python for data visualization and exploration.\n",
       "* Performed analysis of customer purchase order data to provide insights and recommendations to improve business operations.\n",
       "\n",
       "**Data Analyst (Capstone Project)** (2022)\n",
       "* **Ascension Healthcare, St. Louis, MO**\n",
       "\n",
       "* Developed an ETL pipeline to extract, clean, and transform financial data using Python and cloud platforms.\n",
       "* Performed time series analysis to identify financial trends and seasonality patterns.\n",
       "* Built machine learning models for predicting healthcare costs.\n",
       "\n",
       "**Data Science Consulting Intern** (2022)\n",
       "* **Big Data & Analytics, HCR, Beijing, China**\n",
       "\n",
       "* Conducted data mining analysis on customer feedback from online forums and surveys.\n",
       "* Built NLP models for extracting insights from unstructured text data.\n",
       "* Performed cluster analysis to identify distinct customer segments based on their needs and preferences.\n",
       "\n",
       "**LDATopic Extraction for Vaccine Discourse** (2021)\n",
       "\n",
       "* Developed an NLP pipeline for extracting key topics and sentiment from vaccine-related articles, research papers, and social media data.\n",
       "* Used topic modeling to analyze the evolution of public discourse on vaccines over time.\n",
       "* Identified emerging trends and insights relevant to vaccine development, communication, and public understanding.\n",
       "\n",
       "**Business Analyst** (2019)\n",
       "* **Northeastern Accounting Department, Boston, MA**\n",
       "\n",
       "* Developed Power BI dashboards to visualize key financial metrics for budget planning and performance analysis.\n",
       "* Conducted ad-hoc data analysis to support departmental decision-making.\n",
       "\n",
       "**SKILLS & TECHNOLOGIES**\n",
       "\n",
       "* Programming Languages: Python, SQL, R\n",
       "* Data Engineering: Airflow, Spark, AWS, GCP\n",
       "* Machine Learning: Scikit-learn, TensorFlow, PyTorch\n",
       "* NLP Libraries: NLTK, Gensim, spaCy\n",
       "* Cloud Computing: AWS EC2, S3, Google Cloud Platform, Azure\n",
       "* Data Visualization: Grafana, Tableau, Power BI\n",
       "* Communication: Excellent communication and presentation skills.\n",
       "* Teamwork: Proven ability to collaborate effectively in a team-oriented environment.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(hypothetical_resume.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d23416-ae85-4752-8c25-783c6f50acf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
